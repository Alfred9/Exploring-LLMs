{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Alfred9/Exploring-LLMs/blob/main/Visual%20Language%20Models/Smol_vlm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import required libraries and set hardware for model to use\n",
        "import torch\n",
        "from PIL import Image\n",
        "from transformers import AutoProcessor, AutoModelForVision2Seq\n",
        "from transformers.image_utils import load_image\n",
        "import requests\n",
        "\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "print(DEVICE)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z9KuqbLlK11U",
        "outputId": "e1335a1a-88fa-4b43-97e2-965e12f12be5"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image1 = load_image(\"https://media.hswstatic.com/eyJidWNrZXQiOiJjb250ZW50Lmhzd3N0YXRpYy5jb20iLCJrZXkiOiJnaWZcL2JlY29taW5nLWRvY3Rvci5qcGciLCJlZGl0cyI6eyJyZXNpemUiOnsid2lkdGgiOjgyOH19fQ==\")\n"
      ],
      "metadata": {
        "id": "YqYJ0KeQUA92"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(image1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bIqI1nq6LFK0",
        "outputId": "9dbb1780-baba-47ec-9716-d8039f1bbbce"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<PIL.Image.Image image mode=RGB size=828x466 at 0x7AE55ACC7E90>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize processor and model\n",
        "processor = AutoProcessor.from_pretrained(\"HuggingFaceTB/SmolVLM-Instruct\")\n",
        "model = AutoModelForVision2Seq.from_pretrained(\n",
        "    \"HuggingFaceTB/SmolVLM-Instruct\",\n",
        "    torch_dtype=torch.bfloat16\n",
        ").to(DEVICE)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xWd6_Wj5LX9V",
        "outputId": "b7ed5ac4-92da-464f-8ef6-a5e6aa18c6b6"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some kwargs in processor config are unused and will not have any effect: image_seq_len. \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create input messages\n",
        "messages = [\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": [\n",
        "            {\"type\": \"image\"},\n",
        "            {\"type\": \"text\", \"text\": \"what is going on in the picture?\"}\n",
        "        ]\n",
        "    },\n",
        "]\n"
      ],
      "metadata": {
        "id": "iDCjZOtWLs36"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare inputs\n",
        "prompt = processor.apply_chat_template(messages, add_generation_prompt=True)\n",
        "inputs = processor(text=prompt, images=[image1], return_tensors=\"pt\")\n",
        "inputs = inputs.to(DEVICE)\n",
        "\n",
        "# print(inputs)"
      ],
      "metadata": {
        "id": "d_PnXexEMQ8A"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Generate outputs\n",
        "generated_ids = model.generate(**inputs, max_new_tokens=500)\n",
        "generated_texts = processor.batch_decode(\n",
        "    generated_ids,\n",
        "    skip_special_tokens=True,\n",
        ")\n",
        "\n",
        "print(generated_texts[0])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "99IqMrQTkOLR",
        "outputId": "9a073ec7-3234-41d0-f851-687b594735d8"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "User:<image>what is going on in the picture?\n",
            "Assistant: The image depicts a group of medical professionals gathered around a patient in a hospital room. The patient is lying in a bed, and the group of doctors and nurses are attentively listening to a conversation or discussion among themselves. The room is equipped with various medical devices and equipment, including a heart rate monitor and an oxygen tank.\n",
            "\n",
            "The group of medical professionals includes a male doctor, a female doctor, and three female nurses. The doctor is wearing a white lab coat and a stethoscope around his neck. He is looking at the patient and appears to be engaged in a conversation with the other medical professionals. The female doctor is wearing a blue top and is holding a tablet, while the female nurses are wearing white tops and are also holding tablets.\n",
            "\n",
            "The patient is lying in a bed with a medical device attached to his chest, which is likely used to monitor his vital signs. The patient is wearing a hospital gown, and his face is partially covered by a mask. The patient is looking towards the group of medical professionals, indicating that he is listening to their conversation.\n",
            "\n",
            "The background of the room is plain, with a white wall and a blue curtain. The room is well-lit, and the overall atmosphere is one of professionalism and seriousness, typical of a hospital setting.\n",
            "\n",
            "The image captures a moment of collaboration and communication among medical professionals, highlighting the importance of teamwork and interdisciplinary efforts in patient care. The presence of the patient and the medical professionals suggests that the patient is receiving medical attention and is being supported by the team.\n",
            "\n",
            "In summary, the image portrays a group of medical professionals in a hospital room, engaged in a conversation or discussion, with the patient lying in a bed and listening attentively. The medical professionals are wearing appropriate attire and are equipped with necessary medical devices, indicating a professional environment focused on patient care.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xYDZOOoBnozq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}